---
layout: post
title:  "缓存 cache"
date:   2022-03-07 2:00:00 +0000
categories: jekyll update
---

# 缓存
缓存是为了解决通信双方速度不一致而导致的通信效率下降的问题，如果没有缓存，高速方和低速方进通信行交互的时候，高速方需要等待低速方，低速方就成了通信瓶颈。一般情况下，高速方从低速方获取的数据在一段时间内都会有重复性（数据局部性data locality），因此，将重复性高的数据“提前”存放在速度较快的缓存中，当高速方再次需要这些数据时直接从速度更快的缓存读取，而不去等待低速方，从而可以大大提高高速方工作效率，同时降低低速方的负担。
## 区别：缓存cache v.s. 缓冲区buffer
缓冲区buffer同样也是为了解决通信双方速度不一致效率下降的问题，只不过buffer关注解决短时间高速方大量发起任务需要低速方处理的峰值压力问题，buffer可以将一段时间内高速方忽高忽低的通信请求进行临时存储，然后按照相对稳定的速度和信息量交给低速方进行处理并返回。总而言之，buffer做的是削峰填谷的整形工作，而cache单纯就是为了提高了通信性能，并降低了低速方的压力。

# 各种层面的缓存
## CPU缓存 
计算机体系结构简化后最基本的通信路径是“cpu-内存-硬盘”，cpu做为计算单元每次执行命令都需要从存储单元（内存、硬盘）读取数据，这个路径上cpu的工作速度是最快的，cpu执行一条指令需要的时间是ns级内的，而内存工作起来因为需要寻址找数据，这个过程产生的延迟大概是几百ns，比cpu慢了几百倍，普通硬盘的寻址速度更慢，延迟可以达到几十ms，比cpu慢了几千万倍，正可谓cpu一秒，要等磁盘一年。

cpu通过内存路径读取硬盘上的数据的这种方式下，可以理解内存就是缓存。实际上，当前的计算机结构中，先抛开慢如蜗牛的硬盘不讲，cpu读取内存中的数据，中间也有缓存机制，并且有多级缓存。现在典型的cpu一般有三级缓存，从一级缓存到三级缓存，分别是速度越来越慢，容量越来越大。Linux操作系统下可以用命令`getconf -a | grep -i cache`查看多级缓存信息。cpu读取数据先查速度最快的一级缓存有没有，如果有（缓存命中）就返回处理，如果没有（缓存命中失败），则去第二级缓存查询，如果命中则返回处理，并将该数据按照一定的机制存储在一级缓存，如果再次命中失败，则往下一级缓存查询，最后不行就去访问内存。

cpu的缓存设备其实也是ram内存家族中的一员，叫静态随机存储器SRAM，其特点是存储速度快，密度小因此容量小（几十k到几百k），造价昂贵；而ram家族的另外一员动态随机存储器DRAM，工作时需要控制刷新电路才能存储数据，因此速度相对较慢，但是比较便宜，DRAM密度大因此相同体积下容量也大（几G到几十G），最终成了现在计算机里内存设备的角色。随着内存容量的指数级提升，寻址产生的延时也在增加，导致了“内存速度再快CPU也需要等待内存”的事实情况，而cpu每次指令工作都要从存储单元获取数据的这种先天性架构定义所导致的性能劣势，被称之为冯·诺依曼瓶颈。近期出现的分布式存储和计算、神经网络、GPU和显存等这些都是在不同领域甚至是基础架构层面尝试解决这个高速计算单元、低速存储单元的通信双方的信息传递怎么高速和平衡的问题。
## 硬盘缓存
硬盘也有高低速之分，高速硬盘固态ssd成功读写一次数据需要耗时大约在一两百us, 因此ssd经常使用内存里面的一两颗DRAM作为缓存，从几十M到几百M；低速硬盘sata容量超级大，但读写数据产生的延时要到几十ms，速度比ssd慢一两百倍，其缓存容量从几M到几十M不等。

测试硬盘性能时，要注意绕过硬盘的缓存机制，linux下常用的I/O工具需要加参数`fio -direct=1 ...`，要不然测试结果就是硬盘缓存也就是内存的I/O性能，而不是硬盘本身的。

## HTTP客户端缓存/浏览器缓存/本地缓存
通过HTTP访问业务服务是现在最为常用的服务访问模式。提供服务的web服务器因为要面向来自众多客户端的请求，经常处于比较繁忙的状态，可以认为是低速方；做为相对比较轻松的单个HTTP客户端，也就是操作系统中安装的浏览器软件，使用HTTP协议标准定义的缓存机制来提高web服务响应速度，改善使用体验，还可以缓解服务端压力。

HTTP协议的客户端缓存机制，大致可以分为如下三种：状态缓存、强制缓存、协商缓存，但不管那种缓存，工作模式都是服务器在对客户端的响应中增加一些协议定义好的头字节，要求客户端在符合特定的条件下，可以直接使用保存在客户端/浏览器里的、缓存下来的上一次响应结果，而不要再次往服务端发送请求并等待服务端再次响应。浏览器时间用的越长，缓存的内容越多，浏览器存储占用的空间也越大。

### 状态缓存
状态缓存缓存的是服务端状态，特指http协议的`服务状态码301`和`服务状态码308`的永久重定向机制，常见场景是：客户端使用http非安全模式访问一个服务网站时，服务网站返回301/308并通过头字段`Location`指定客户端跳转到新的https地址，浏览器根据http协议的约定会永久缓存该状态。这样下一次客户端再次使用http访问该网站时，直接缓存命中，不经过服务器就返回，跳转到https模式后才向真正的服务端发出请求。（返回码301重定向后只能使用GET方法，而308重定向后可以保持POST方法；分别对应的，302/303和307是临时重定向，临时重定向浏览器的默认行为是不缓存）

### 强制缓存
强制缓存是基于时效性判断的缓存处理机制，处理客户端和服务端关于资源一致性的缓存有效期、是否要重新验证缓存、谁可以缓存那些内容等等细节问题，从HTTP1.0的`Expires`字段指定缓存过期时间，发展到后来HTTP1.1的`Cache-Control`字段提供更为丰富的缓存控制机制：

|字段示例|HTTP请求/响应|解释|
|:---|---|:---|
<div style="width: 170pt">`Expires: Mon, 1 Jan 2022 01:00:00 GMT`|<div style="width: 30pt">响应|客户端在指定时间段之前从缓存直接响应，不去请求服务端；服务端保证在这个时间段之前资源没有更新
`Cache-Control: max-age=120`|响应|客户端的缓存有效期为120s，在120s内的再次请求由缓存直接响应；120s后缓存失效，请求发往服务器，服务器检查内容：若无更新，返回304，客户端仍然去缓存拿数据，若有更新，返回200和新内容，客户端本地更新缓存新内容（这个过程叫`重新验证revalidate`）
`Cache-Control: max-age=0`|请求/响应|请求：客户端请求路径上的点的缓存都需要服务端进行重新验证，服务端返回304或200</br>响应：客户端应该SHOULD需要服务端重新验证缓存，服务端返回304/200
`Cache-Control: no-cache`|请求/响应|请求：请客户端和求路径上的点的缓存不需要服务端对缓存进行重新验证，需要服务端处理请求，返回200</br>响应：客户端一定MUST需要服务端重新验证缓存，服务端返回304/200
`Cache-Control: no-store`|响应|这个才是禁用缓存(`no-cache`不是），客户端和路径上的CDN都不要缓存该资源
`Cache-Control: must-revalidate`|响应|客户端的缓存失效后，默认行为就是需要服务器端重新验证的，该字段指定了客户端一定MUST要发往服务器端进行重新验证，它禁止了可以使用过期缓存的某些特殊情况：比如校验请求发送失败时，或使用一些特殊扩展指令例如Cache-control: stale-if-error=200s
`Cache-Control: public` </br> `Cache-Control: private`|响应|public代表该资源公开，响应路径上的客户端、代理、CDN都可以缓存，private代表资源私有，只能客户端缓存。

### 协商缓存
协商缓存是基于变化检测的缓存处理机制，需要客户端和服务器端进行信息协商交互来确定缓存怎么使用，比如HTTP1.0里定义的资源修改时间`Last-Modified`，HTTP1.1里定义的资源唯一标识符`Etag`。

|字段示例|HTTP请求/响应|解释|
|:---|---|:---|
|<div style="width: 100pt">Last-Modified|<div style="width: 30pt">响应|服务器端标注该资源的最后修改时间，客户端记录下来。通常情况下，不太经常改动的静态资源文件例如css、图片等都会附带该信息
|If-Modified-Since|请求|客户端请求相同资源的时候，会附带记录的最后修改时间，服务器端检查该时间，如果该时间之后没有更新，则返回304要求客户端使用缓存内的数据，如果已经更新，则返回200和已经更新的内容，以及Last-Modified时间供客户端更新记录
|Etag|响应|服务器端对资源进行包括修改时间等内容的hash生成的唯一标识符发送给客户端，客户端记录
|If-None-Match|请求|客户端请求相同资源的时候，会附带记录的唯一标识符，服务器端检查该标识符，如果没有更新，则返回304要求客户端使用缓存内的数据，如果已经更新，则返回200和已经更新的内容，以及更新后重新计算的唯一标识符供客户端更新记录
|Date|请求/响应|产生消息时的GMT时间。客户端获取响应后查看该字段，如果比自己发请求时的时间还早，则知道响应来自于缓存
|Age|响应|代理缓存标注其缓存的响应资源时间从产生到现在过了多长时间了，客户端段可以据此判断缓存内容的新鲜程度。Age接近于0代表响应是直接从服务器端获取到的
|Vary|响应|内容协商机制标志性字段。服务端一般针对不同的客户端会有不同版本的内容回复，Vary里面是一堆请求头字段的列表，用来告诉客户端/代理缓存内容时根据什么来筛选和判断后才能正确响应，比如`Vary: User-Agent, Accept-Encoding`表示该响应的资源要直接通过缓存回复客户端时，需要根据请求头中的这两个字节的内容来了解客户端类型和编码类型并筛选对应的响应回复内容

### 客户端缓存里和用户凭证相关的机制和存储机制：cache storage/cookie/session storage/local storage/token/JWT

![cache and others]({{ site.url }}/images/cache-1.png)

- 缓存存储cache storage，主要存储上面描述的三种缓存机制下的响应回复热点数据,例如一些静态文件和图片等。

实际上，客户端使用“缓存”方法保存的内容，除了缓存数据外，还有cookie/回话存储session storage/本地存储local storage里面的各种数据。缓存cookie/session主要是解决HTML协议天生无状态设计的情况下，仍然有一些必要场景比如用户凭证的保存，需要用户保存一些有状态数据的问题。除了用户凭证的相关数据，cookie/session storage都可以存储别的必要内容，cookie的容量小只有4K，而session storage和local storage都可以到5M，更大的数据需要缓存时可以使用对象存储IndexedDB，能到几百兆。

在使用cookie缓存数据的场景中，服务端发送给客户端的响应中增加了`Set-Cookie`的头，里面给客户端分配了名字用作连接标识，例如`Set-Cookie: id=client1 ...`，要求客户端缓存该名字并在以后的请求中都增加头`Cookie: id=client1`，这样服务器端就知道请求是从哪个客户端发来的了。cookie存储的内容都是明文的，为了更加安全，引入了session机制：服务端发给客户端一串无意义字符（客户端无法预先猜出来）做为`SessionId`，客户端将其缓存下来并在后面的每一次请求中发送该SessionId，服务端根据SessionId在服务器本地（一般在内存中）维护一张SessionId和用户及其对应状态、过期时间等的一张数据表用以管理和维护。session基于cookie实现（一般将sessionId存放于cookie中），实际情况中考虑会有浏览器禁用cookie的情况，所以也可以同时编程实现将SessionId存放在其它地方，放在请求的url里面作为参数`http://...?sessionid=xxx`传输。

- cookie：cookie由超文本传输协议HTTP定义，技术老所以兼容性好，每次发送请求都要附带上，有过期时间，如果不设置过期时间则浏览器关闭就会清理cookie；浏览器的隐私模式会禁用cookie。cookie常用的场景有：自动登录，上一次最后访问的页面，访问量统计。
`sessionID`一般以key:value形式存储在cookie中，而对应的session详情一般存在服务器端的内存中。session常用的场景有：购物车，预订酒店等。禁用cookie的场景中使用session，可以将sessionID存储在session storage或其它本地目录，传输时放在url参数里面或者`Authorization头`发送给服务端。

- session storage：超文本标记语言HTML5定义，不同的域名下有不同的存储区域（跨域问题的原因），不在不同的浏览器和书签之间共享，关闭页面回话结束后会自动清理该内容，是临时存储。
- local storage：超文本标记语言HTML5定义；不同的域名有不同的存储区域；可以在不同的浏览器和书签之间共享；关闭页面后，数据内容继续保留，是永久存储，除非主动去删除。

因为session storage和local storage这两种和HTTP这种客户端/服务端C/S模式的传输协议不存在直接关系，所以也有一种分类会把cache、cookie叫做HTTP客户端缓存机制，而session storage、local storage这两种web storage叫本地缓存机制。

cookie-session的工作模式把维护用户连接状态的任务放在了服务器端，对于多个客户端一个服务端的访问模式是最佳的，但对于分布式服务的一个客户端多个服务端的访问模式，就有问题了，用户想保持连接状态下的这一次请求去往服务实例1，session详情保存在了服务实例1的内存中，但下一次请求可能被负载均衡路由到了服务实例2，服务实例2没有匹配该sessionId的信息，服务就会认为该请求是另一个用户端的而返回一个新的sessionId。解决该问题的方法，要么在所有服务端复制session信息从而实现session共享，例如在nginx_tomcat_redis_mysql的典型架构中，通过在tomcat中加载RedisSessionManager组件配置实现，会占用额外的内存和网络资源；要么使用和cookie工作类似的客户端缓存一切模式的token/JWT机制。

- token：客户端通过用户名和密码登录服务端，服务端判断认证信息正确后，将认证信息进行数字签名和加密后发回一个令牌token，客户端将token缓存在本地存储localstorage或直接放入cookie中，并在后面的每一次请求中携带该token，服务端对token进行解密和签名认证后判断其有效性，返回响应。token里存储的是用户的唯一标识，有效期等；服务端不需要存储token因为服务端可以解密token并获取信息，或者服务器将token中的userid部分等其它相关信息存储在数据库里用以管理生命周期，例如签发了多少token，token的描述内容，哪个token快过期了等。服务端以页面提供token的时候，通常提示用户自己本地保存一份，并且警告若后面丢失无法重新找回。
- JWT（JSON Web Token）：JWT是目前最广泛使用的oauth 2认证令牌格式，它携带加密算法和一定量的认证信息，并对这两部分内容进行加密签名后形成无法篡改的可信标识，JWT的签名部分是由服务器的私钥和公开的特定签名算法对信息内容进行加密计算的结果，保证了凭证不会被中间人篡改，服务器端收到后使用本地存储并保密的私钥来解密获取认证信息。一般使用中也是将JWT放入`Authorization`请求头中发送，并以Bearer开头: `Authorization: Bearer xyzxyzxyzxyz...`

## 网络缓存

客户端和服务端进行数据交互的路径上，常见的网络设备/服务有代理服务和CDN网络设备。代理重点关注于HTTP访问特殊资源的实现或者对具有某种特征的访问进行路由分发，但可以加持对热点数据进行缓存的功能，直接代理服务端响应客户端请求；CDN设备本身就是做为缓存服务器而生的，CDN网络可以加速静态资源的分发，响应用户客户端的请求、缓存服务端的数据更新，除了这些缓存服务表现外，CDN还可以扩展出其它更丰富的管理功能，例如安全防护、广告注入等。

需要提一下的是，HTTP缓存机制中针对客户端和网络缓存端有针对性的头字节定义，标准化了客户端和网络缓存端对缓存数据的内容、过期时间等的不同行为表现，而实际上，网络缓存设备可以忽视这些标准而正常工作，例如，某个代理服务可被设置为故意缓存标识为`Cache-Control: private`的客户私有资源，用做特殊用处。
### 代理缓存
正向代理、反向代理和透明代理在网络位置上位于客户端和服务器的中间，工作在七层，主要有下面三种：

- 正向代理，代理客户端，客户端需要自己配置代理，服务器端看到的业务流量来自于代理。
- 透明代理，拦截并处理客户端的业务流量，客户端无需自己配置代理，服务器端看到的业务流量来自于代理，但服务器端可以看到客户端的真实IP地址。
- 反向代理，代理服务器端，客户端看到的业务流量来自于代理。

代理服务可以嗅探到HTTP报文的全部内容，因此实现缓存功能是顺理成章的。代理缓存进一步缓解了服务端的压力，提升了客户端的响应效率，并且因为代理服务通常都是内部人员/网络运营商来自主管理，可以实现更多的安全管控能力和增值业务。

### 边缘缓存/CDN
边缘缓存的典型实现是CDN（Content Distribution Netwrok）产品和服务，当用户在浏览器键入一个url进行访问时，url的第一部分`域名`会被`DNS服务器`解析，如果没有CDN网络，DNS服务器会直接将域名解析为服务端的公网IP地址（DNS的A记录），请求就会根据路由表信息进行下一步IP寻址；如果有CDN网络已经在DNS上注册过，DNS服务器会将域名解析为CDN网络注册的域名（DNS的CNAME记录），该域名只能由CND网络服务商建设的DNS服务器解析，通过一整套算法，最终返回给用户延时最小（通常地理位置上也是离用户最近）的CDN服务器的IP地址，这样用户就和CND服务器建立起通信连接，快速获取CDN服务器的缓存资源内容；如果访问需求的资源CDN服务器没有被缓存或需要更新，则请求会被发送给真实的服务端并响应，CDN也会缓存最新的内容准备后面的访问应答，这种工作模式叫“被动回源”，对客户端和服务端透明。CDN服务还有一种工作模式叫“主动分发”，需要服务器端感知CDN服务的存在并主动发起特定内容的推送，CDN服务器被动缓存这些新的内容。

如果单纯的做内容分发，仅仅提供边缘缓存服务，CDN服务网络的商业性价比是不高的，因为处在边缘，需要多点部署才能尽可能的邻近各个客户端，同时，CDN服务器的物理性能配置通常也是要求也比较高的。实际生产环境下，除了缓存静态资源实现内容的加速分发外，CDN服务做为另外一个可以窥探到所有用户请求和服务端响应的中间设备，可以提供更丰富的功能注入例如广告、安全防护例如防止DDoS、访问控制例如黑白名单、QoS、防盗链等。
## 服务端缓存
服务端应用的组成是比较复杂的，但一般都会有后台数据库，存储需要持久化的数据，而数据库读写操作是I/O类型的，相对于服务端应用的计算部分，硬盘数据读取和内存加载都是慢速方。随着服务端应用业务压力的增加，例如当一次请求要读写上千调数据库内容时，服务端应用必须使用缓存服务来平衡和提高系统的整体性能。
### 进程内缓存
应用如果考虑使用进程内缓存，主流的解决方案可选择`Guava`、`Caffeine`等。进程内缓存组件一般以基于特定编程语言的函数库的形式出现，对应用的代码侵入性比较高，但使用起来也更灵活、更高效。

最简单的进程内缓存解决方案，可以理解一下linux系统的命令缓存机制：用户在linux键入命令后，需要在`PATH`的所有路径下查询该命令的全路径以找到执行文件，这个过程是相对慢速的，因此查询到该命令后会将该命令对应的执行文件的全路径做为热点数据记录在hash表中（linux命令`hash`），并标志命中1次，下次再敲入该命令后，先找hash表，如果没有才会在`PATH`路径下搜索。

商业级主流的进程内缓存要考虑更多的事情，例如怎么提高缓存响应的吞吐量，提高缓存命中率，什么条件下失效缓存数据等：

- `命中率和淘汰机制`：缓存空间的有限性以及性能需求决定了缓存内数据是需要有淘汰机制的，不能无限制的增加。类似上面举的linux命令缓存机制的例子，缓存中的数据被使用一次，就是命中一次，一段时间内命中次数和总请求次数的比就是命中率，命中率越高的缓存系统，其体现出的价值也越高。缓存系统会记录一些必要的缓存命中的统计数据比如次数、时间等，并制定淘汰机制自动清除掉一些被认定为非热点的数据，最基本的淘汰机制例如有：先进先出FIFO, `最老未被访问的数据LRU`, `最少被访问的数据LFU`, 最近有发展出来性能更好也更复杂的淘汰机制，例如TinyLFU，W-TinyLFU，ARC，LIRS等，大大提高了缓存的命中率。当然，应用也可以自己编写适合的缓存淘汰机制。

- `吞吐量`：进程内并发线程存在同时对缓存数据进行读写操作的情况，叠加缓存统计数据例如读缓存次数、时间的更新，怎么处理这些状态的维护和数据的一致性，决定了一个缓存系统的吞吐量的高低。不同的商业解决方案有不同的机制，但一般都是通过加同步锁、改异步等方法实现的。

- `失效机制`：缓存数据一般会设置在经过一定的时间后过期被移除，缓存服务的中断重启，或者是主动发起的缓存区数据刷新机制，同样也都会造成缓存失效，缓存失效后大量的读写请求会压在后端数据中，造成系统性能下降甚至不正常，因此需要有对应的失效机制。最常见的缓存失效机制是通过设定缓存过期时间为随机值而不是固定值来解决缓存失效问题。
### 分布式缓存
应用考虑分布式的缓存的话，可选择`redis`、`memchached`等。使用集群的模式提供缓存服务功能的就是分布式缓存，按照工作模式的不同，分布式缓存可以分为复制工作模式和集中工作模式。复制工作模式的分布式缓存例如`JBossCache`，热点数据在集群节点之间以复制的形式同步，直到每个节点都会有一份数据的副本，使用该缓存的应用部署在缓存集群的这些节点上，通过本地内存读取数据，读取性能很高，但当集群规模变大、热点数据更新时，集群节点之间需要大量的具有高延时特性的网络通信来复制更新，导致缓存性能急剧下降甚至系统内存耗尽。集中工作式的分布式内存，读写数据都需要通过网络访问，但节点之间不需要同步复制数据，并且集中式工作的分布式内存通常是独立的集群模式部署，应用程序通过C/S socket访问来使用缓存，因此集中式工作的分布式缓存在使用过程中除了网络延时的传输成本外，还有序列化/反序列化的成本，但这种解耦的架构也带来了可以兼容异构语言的好处。分布式缓存同样遵循CAP理论，业内目前最常用的解决方案redis是AP型，强调高可用性，而memcached和JBossCache都是CP型，强调数据一致性。

分布式缓存处理的问题首先是因为不可靠的网络带来的吞吐量的下降，然后和进程内缓存一样它也要考虑命中率淘汰机制有、失效机制这些事情。和应用程序解耦后的分布式缓存提供了更好的伸缩性，这使得缓存性能的提升好像也没了上限，并且可以作为基础设施进行单独管理维护，好处多多，同时分布式缓存也增加了技术复杂度，带来了不可避免的新的风险，需要在设计和使用中注意：

- 缓存穿透cache penetration: 请求的数据在数据库、缓存里都不存在，这样请求会持续对数据库产生压力，系统性能下降。

    * 缓存空对象：一定时间内，缓存某某key值为空的数据对象，并响应下一次请求；后续该key值的数据在数据库里更新时，业务逻辑上要清理对应缓存中的数据。
    * 缓存前置布隆过滤器BloomFilter：布隆过滤器由一个很长的二进制向量以及多个hash函数组成，可以高效的判断一个数据元素一定不在集合里、或有可能在集合里。如果请求的数据key值经过判断一定不在数据库中，则由布隆过滤器直接响应请求返回，不请求缓存和数据库；如果判断有可能存在，则先查询缓存，缓存中不存在再查询数据库。

- 缓存击穿cache breakdown：请求的热点数据因为特定原因例如到了过期时间后失效，刚好有多个请求同时要查询该数据，数据库繁忙，系统性能持续下降。

    * 加锁：第一个请求查询失效后的缓存数据时，需要查询数据库并重建缓存内的该数据，这个过程中，进程内缓存加互斥锁/分布式缓存加分布式锁，后续的请求直接阻塞或者等待重试，防止对数据库的持续增压。
    * 设置缓存数据失效时间为永不过期： 取消缓存的自动失效机制，代码中编写逻辑实现缓存数据的主动更新/刷新，或者规避了缓存击穿问题的特定时间后的删除（其实就是自定义的失效机制）。

- 缓存雪崩cache avalanche： 缓存击穿的加强版，如果一段时间内，缓存系统内的数据因为缓存节点冷启动或缓存服务重启等原因而发生了集中失效，大量的请求就会直接压在数据库上，系统接近于奔溃。

    * 分布式缓存采用高可用架构，确保单点故障下对外服务的正常提供，典型的如redis ha/redis sentinel
    * 同一缓存系统内缓存数据的失效时间避免设置成唯一确定值，可以采用基于特定值随机范围的随机值，使缓存数据分散性失效重建。

- 缓存无底洞cache multiget hole：分布式缓存集群规模和业务规模达到一定程度后，再增加分布式缓存的集群节点，也不会提高缓存性能现象称之为缓存无底洞。缓存无底洞的现象最早是由facebook的工程师维护3000个节点的存储了数千G缓存数据的memcached集群时发现的。

    * 避免mget操作： 业务查询的逻辑上实现尽可能避免一次请求包含多个热点数据的mget操作，对于规模庞大的分布式缓存，查询数据在哪个节点以及网络I/O的量都会急剧增加。如果是在是避免不了mget操作，则要针对mget的实现进行优化以降低时间复杂度，减少网络请求次数。
    * 保持小规模：可以通过分区域、分集群甚至是分项目建设各自的缓存机制，保持特定资源下业务量和分布式集群规模的可控。
    * 优化请求命令，优化sql命令

- 缓存污染cache pollution/full: 缓存中保存了大量不是热点的数据，把缓存空间占满了，导致新的热点数据缓存时，还需要等待数据淘汰过程，系统整体性能下降。
    * 设置缓存过期时间，过期后删除
    * 执行缓存淘汰机制LRU/LFU等
    * 自定义定时删除缓存

- 缓存和数据库数据不一致inconsistency： 缓存中的数据和数据库中的数据不一致，比数据库对应key里面的数据或新一些，例如：缓存写正确，但是数据库写失败；或旧一些，例如：数据库写成功，而缓存没做更新，这些问题的出现一般是代码处理缓存逻辑的时候发生了问题。可以根据业务系统特征选用不一样的缓存设计模式，严格遵循实现代码：
    * 旁路缓存Cache Aside：读：缓存命中cache hit后返回响应，缓存未命中cache miss后读数据库、并回写更新缓存，然后返回响应。写：更新数据库、删除缓存中对应数据。特点是以数据库为主，强调缓存和数据库的数据一致性，应用代码逻辑需要维护两个数据存储区域，复杂度高。
    * 读写穿透Read/Write Through：读：缓存命中hit后返回响应，缓存未命中miss后读数据库、并回写更新缓存，然后返回响应。写：如果缓存中无该数据，不操作缓存、只更新数据库；如果缓存中有该数据，更新缓存、更新数据库（一次事务写操作）。特定是应用只访问缓存，由缓存来决定数据库读写逻辑，代码更简洁，缓存使用效率也更高，也保证了数据一致性。银行系统的分布式缓存通常采用这种模式。
    * 异步缓存写入Write Behind Caching：读：缓存命中hit后返回响应，缓存未命中miss后读数据库、并回写更新缓存，然后返回响应。写：如果缓存中无该数据，不操作缓存、只更新数据库；如果缓存中有该数据，只更新缓存，数据库的更新通过异步批量的方式执行。特定除了应用只访问缓存外，缓存写的效率最高、数据库的压力最小，适合数据变化特别频繁、或者可以聚合的业务，例如点击量统计，代价是失去了一定的数据一致性。
### 多级缓存结构

实际应用中，进程内缓存和分布式缓存可以同时存在，每一级侧重处理特定缓存问题，例如：在Nginx本地缓存静态资源用来解决热点缓存问题，同时提供反向代理服务；nginx后面连接redis分布式缓存用来减少客户端请求直接访问数据库的压力；nginx同时连接Tomcat应用服务器，tomcat本地使用堆缓存部分数据库数据，通过服务治理逻辑，防止redis缓存失效或雪崩之后对数据库的冲击。在这种多级缓存结构中，多级缓存的先后查询以及回填逻辑需要进行封装，对外提供统一的单一接口供调用，对内通常以分布式缓存内的数据准确性为主，以本地进程内缓存的数据主要提供响应返回，利用各级缓存的特点和优势最大限度的提高整体缓存性能。